{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About This Notebook\n",
    "\n",
    "This notebook is based on https://www.kaggle.com/konradb/model-train-efficientnet & https://www.kaggle.com/konradb/model-infer-efficientnet, with a final score of 8.90 achieved in the BMS competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import cv2\n",
    "import timm\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, Blur\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input Data\n",
    "> Import the train dataframe containing image IDs, InChI strings, their actual lengths and parsed sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the input data contained in the pickle file saved previously\n",
    "train_df = pd.read_pickle('../../data/train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add File Paths\n",
    "> Make the process of reading the input data more efficient by storing paths to files in the train dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(image_id: str) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    This method returns the paths to train images by indexing into the overall directory\n",
    "    and the image_id's components.\n",
    "    \n",
    "    :param image_id: ID of the image\n",
    "    :type  image_id: str\n",
    "    :return:         path to image\n",
    "    :rtype:          str\n",
    "    \"\"\"\n",
    "    \n",
    "    # index into original train images if '-' is not present\n",
    "    return '../../data/bms-molecular-translation/train/{}/{}/{}/{}.png'.format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file paths\n",
    "train_df['file_path'] = train_df['image_id'].apply(get_file_path)\n",
    "train_df.to_csv('../../data/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the file back\n",
    "train_df = pd.read_csv('../../data/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to Â±300K data sub-selected by size 200-350 (HxW)\n",
    "valid_ids = pd.read_csv('../../data/bmssmalldataset/new_dataset.csv')['image_id']\n",
    "train_df  = train_df[train_df['image_id'].isin(valid_ids)]\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(train_df) * 0.8)\n",
    "\n",
    "# keep 20% as test dataset\n",
    "test_df   = train_df.loc[train_len:, :]\n",
    "\n",
    "# keep 80% as train dataset\n",
    "train_df  = train_df.loc[:train_len, :]\n",
    "\n",
    "# save as csv files\n",
    "test_df.to_csv('../../data/test.csv')\n",
    "train_df.to_csv('../../data/reduced_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "> This is a set of utility functions used throughout the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_true: str, y_pred: str) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes the Levenstein distance between a true label and a prediction.\n",
    "    This gets computed for all the provided data and an average score is then returned.\n",
    "    \n",
    "    :param y_true: true InChI label\n",
    "    :type  y_true: str\n",
    "    :param y_pred: predicted InChI label\n",
    "    :type  y_pred: str\n",
    "    :return:       average Levenstein score\n",
    "    :rtype:        float\n",
    "    \"\"\"\n",
    "    \n",
    "    # storage for all Levenstein scores\n",
    "    scores = []\n",
    "    \n",
    "    # for each (true label, predicted label) pair, do\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        \n",
    "        # find Levenstein distance for the pair and append to storage\n",
    "        score = Levenshtein.distance(true, pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    # compute mean Levenstein distance\n",
    "    avg_score = np.mean(scores)\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Predictions and Valid Labels for Each InChI Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload predictions for each InChI part\n",
    "\n",
    "inchi_1_preds = np.load('../../data/inchi1-predictions.npy')\n",
    "inchi_2_preds = np.load('../../data/inchi2-predictions.npy')\n",
    "inchi_3_preds = np.load('../../data/inchi3-predictions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload valid labels for each InChI part\n",
    "\n",
    "inchi_1_valid_labels = np.load('../../data/inchi1-validations.npy')\n",
    "inchi_2_valid_labels = np.load('../../data/inchi2-validations.npy')\n",
    "inchi_3_valid_labels = np.load('../../data/inchi3-validations.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Total InChI Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total InChI prediction\n",
    "interim_preds = np.add(inchi_1_preds, inchi_2_preds) \n",
    "final_preds   = np.add(interim_preds, inchi_3_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total InChI validation label\n",
    "interim_valid_labels = np.add(inchi_1_valid_labels, inchi_2_valid_labels)\n",
    "final_valid_labels   = np.add(interim_valid_labels, inchi_3_valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Combined Mean Levenshtein Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ld_score = get_score(final_valid_labels, final_preds)\n",
    "print(total_ld_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
