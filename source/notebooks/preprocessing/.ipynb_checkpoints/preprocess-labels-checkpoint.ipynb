{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-21T16:54:40.717786Z",
     "iopub.status.busy": "2022-03-21T16:54:40.717508Z",
     "iopub.status.idle": "2022-03-21T16:54:40.722936Z",
     "shell.execute_reply": "2022-03-21T16:54:40.722340Z",
     "shell.execute_reply.started": "2022-03-21T16:54:40.717757Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-processing\n",
    "\n",
    "### Create a combined dataframe\n",
    "> This creates a dataframe containing the image IDs & labels for both original images provided by the Bristol Myers Squibb pharmaceutical company, and the augmentations generated per each original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T16:54:40.724639Z",
     "iopub.status.busy": "2022-03-21T16:54:40.724286Z",
     "iopub.status.idle": "2022-03-21T16:54:49.058042Z",
     "shell.execute_reply": "2022-03-21T16:54:49.055031Z",
     "shell.execute_reply.started": "2022-03-21T16:54:40.724604Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/bms-molecular-translation/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InChI pre-processing\n",
    "> This, firstly, splits the first part of the InChI string (the chemical formula) into sequences of text and numbers. Secondly, this splits the second part of the InChI string (the other layers) into sequences of text and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T16:54:49.065292Z",
     "iopub.status.busy": "2022-03-21T16:54:49.063458Z",
     "iopub.status.idle": "2022-03-21T16:54:49.085764Z",
     "shell.execute_reply": "2022-03-21T16:54:49.083537Z",
     "shell.execute_reply.started": "2022-03-21T16:54:49.065195Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_inchi_formula(formula: str) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    This function splits the chemical formula (in the first layer of InChI) \n",
    "    into its separate element and number components.\n",
    "    \n",
    "    :param formula: chemical formula, e.g. C13H20OS\n",
    "    :type formula:  string\n",
    "    :return:        splitted chemical formula\n",
    "    :rtype:         string\n",
    "    \"\"\"\n",
    "    \n",
    "    string = ''\n",
    "    \n",
    "    # for each chemical element in the formula\n",
    "    for i in re.findall(r\"[A-Z][^A-Z]*\", formula):\n",
    "        \n",
    "        # return each separate element, i.e. text\n",
    "        elem = re.match(r\"\\D+\", i).group()\n",
    "        # return each separate number\n",
    "        num  = i.replace(elem, \"\")\n",
    "        # add either the element or both element and number (space-separated) to the string \n",
    "        if num == \"\":\n",
    "            string += f\"{elem} \"\n",
    "        else:\n",
    "            string += f\"{elem} {str(num)} \"\n",
    "    \n",
    "    return string.rstrip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T16:54:49.121850Z",
     "iopub.status.busy": "2022-03-21T16:54:49.119793Z",
     "iopub.status.idle": "2022-03-21T16:54:49.156168Z",
     "shell.execute_reply": "2022-03-21T16:54:49.154762Z",
     "shell.execute_reply.started": "2022-03-21T16:54:49.121702Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_inchi_layers(layers: str) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    This function splits the layers (following the first layer of InChI)\n",
    "    into separate element and number components.\n",
    "    \n",
    "    :param layers: layer string, e.g. c1-9(2)8-15-13-6-5-10(3)7-12(13)11(4)14/h5-7,9,11,14H,8H2,1-4H3\n",
    "    :type layers:  string\n",
    "    :return:       splitted layer info\n",
    "    :rtype:        string\n",
    "    \"\"\"\n",
    "    \n",
    "    string = ''\n",
    "    \n",
    "    # for each layer in layers\n",
    "    for i in re.findall(r\"[a-z][^a-z]*\", layers):\n",
    "        # get the character preceding the layer info\n",
    "        elem = i[0]\n",
    "        # get the number string succeeding the character\n",
    "        num  = i.replace(elem, \"\").replace(\"/\", \"\")\n",
    "        num_string = ''\n",
    "        \n",
    "        # for each number string\n",
    "        for j in re.findall(r\"[0-9]+[^0-9]*\", num):\n",
    "            # get the list of numbers\n",
    "            num_list = list(re.findall(r'\\d+', j))\n",
    "            # get the first number\n",
    "            _num = num_list[0]\n",
    "            # add the number string to the overall result\n",
    "            if j == _num:\n",
    "                num_string += f\"{_num} \"\n",
    "            else:\n",
    "                extra = j.replace(_num, \"\")\n",
    "                num_string += f\"{_num} {' '.join(list(extra))} \"\n",
    "    \n",
    "        string += f\"/{elem} {num_string}\"\n",
    "\n",
    "        return string.rstrip(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize texts and predict captions\n",
    "> This tokenizes each text by converting it to a sequence of characters. Backward compatibility is also maintained, i.e. sequence to text conversion. Image caption predictions also take place within the Tokenizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T16:54:49.175425Z",
     "iopub.status.busy": "2022-03-21T16:54:49.175038Z",
     "iopub.status.idle": "2022-03-21T16:54:49.197475Z",
     "shell.execute_reply": "2022-03-21T16:54:49.196655Z",
     "shell.execute_reply.started": "2022-03-21T16:54:49.175385Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # string to integer mapping\n",
    "        self.stoi = {}\n",
    "        # integer to string mapping\n",
    "        self.itos = {}\n",
    "    \n",
    "    def __len__(self) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method returns the length of token:index map.\n",
    "        \n",
    "        :return: length of map\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        # return the length of the map\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_texts(self, texts: list) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method creates a vocabulary of all tokens contained in provided texts,\n",
    "        and updates the mapping of token to index, and index to token.\n",
    "        \n",
    "        :param texts: list of texts\n",
    "        :type texts:  list\n",
    "        \"\"\"\n",
    "        \n",
    "        # create a storage for all tokens\n",
    "        vocab = set()\n",
    "        \n",
    "        # add tokens from each text to vocabulary\n",
    "        for text in texts:\n",
    "            vocab.update(text.split(' '))\n",
    "            \n",
    "        # sort the vocabulary in alphabetical order\n",
    "        vocab = sorted(vocab)\n",
    "        \n",
    "        # add start, end and pad for sentence\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        \n",
    "        # update the string to integer mapping, where integer is the index of the token\n",
    "        for i, s in enumerate(vocab):\n",
    "            self.stoi[s] = i\n",
    "        \n",
    "        # reverse the previous vocabulary to create integer to string mapping\n",
    "        self.itos = {item[1]: item[0] for item in self.stoi.items()}\n",
    "        \n",
    "    def text_to_sequence(self, text: str) -> list:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method converts the given text to a list of its individual tokens,\n",
    "        including start and end of string symbols.\n",
    "        \n",
    "        :param text: input textual data\n",
    "        :type  text: str\n",
    "        :return:     list of tokens\n",
    "        :rtype:      list\n",
    "        \"\"\"\n",
    "        \n",
    "        # storage to append symbols to\n",
    "        sequence = []\n",
    "        \n",
    "        # add the start of string symbol to storage\n",
    "        sequence.append(self.stoi['<sos>'])\n",
    "        \n",
    "        # add each token in text to storage\n",
    "        for s in text.split(' '):\n",
    "            sequence.append(self.stoi[s])\n",
    "            \n",
    "        # add the end of string symbol to storage\n",
    "        sequence.append(self.stoi['<eos>'])\n",
    "        \n",
    "        return sequence\n",
    "    \n",
    "    def texts_to_sequences(self, texts: list) -> list:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method converts each text in the provided list into sequences of characters.\n",
    "        Each sequence is appended to a list and the said list is returned.\n",
    "        \n",
    "        :param texts: a list of input texts\n",
    "        :type  texts: list\n",
    "        :return:      a list of sequences\n",
    "        :rtype:       list\n",
    "        \"\"\"\n",
    "        \n",
    "        # storage to append sequences to\n",
    "        sequences = []\n",
    "        \n",
    "        # for each text do\n",
    "        for text in texts:\n",
    "            # convert the text to a list of characters\n",
    "            sequence = self.text_to_sequence(text)\n",
    "            # append the lists of characters to an aggregated list storage\n",
    "            sequences.append(sequence)\n",
    "\n",
    "        return sequences\n",
    "    \n",
    "    def sequence_to_text(self, sequence: list) -> str:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method converts the sequence of characters back into text.\n",
    "        \n",
    "        :param sequence: list of characters\n",
    "        :type  sequence: list\n",
    "        :return:         text\n",
    "        :rtype:          str \n",
    "        \"\"\"\n",
    "        # join the characters with no space in between\n",
    "        return ''.join(list(map(lambda i: self.itos[i], sequence)))\n",
    "    \n",
    "    def sequences_to_texts(self, sequences: list) -> list:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method converts each provided sequence into text and returns all texts inside a list.\n",
    "        \n",
    "        :param sequences: list of character sequences\n",
    "        :type  sequences: list\n",
    "        :return:          list of texts\n",
    "        :rtype:           list\n",
    "        \"\"\"\n",
    "        \n",
    "        # storage for texts\n",
    "        texts = []\n",
    "        \n",
    "        # convert each sequence to text and append to storage\n",
    "        for sequence in sequences:\n",
    "            text = self.sequence_to_text(sequence)\n",
    "            texts.append(text)\n",
    "\n",
    "        return texts\n",
    "    \n",
    "    def predict_caption(self, sequence: list) -> str:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method predicts the caption by adding each symbol in sequence to a resulting string.\n",
    "        This keeps happening up until the end of sentence or padding is met.\n",
    "        \n",
    "        :param sequence: list of characters\n",
    "        :type  sequence: list\n",
    "        :return:         image caption\n",
    "        :rtype:          string\n",
    "        \"\"\"\n",
    "        \n",
    "        # storage for the final caption\n",
    "        caption = ''\n",
    "        \n",
    "        # for each index in a sequence of symbols\n",
    "        for i in sequence:\n",
    "            # if symbol is the end of sentence or padding, break\n",
    "            if i == self.stoi['<eos>'] or i == self.stoi['<pad>']:\n",
    "                break\n",
    "            # otherwise, add the symbol to the final caption\n",
    "            caption += self.itos[i]\n",
    "            \n",
    "        return caption\n",
    "    \n",
    "    def predict_captions(self, sequences: list) -> list:\n",
    "        \n",
    "        \"\"\"\n",
    "        This method predicts the captions for each sequence in a list of sequences.\n",
    "        \n",
    "        :param sequences: list of sequences\n",
    "        :type  sequences: list\n",
    "        :return:          list of final image captions\n",
    "        :rtype:           list\n",
    "        \"\"\"\n",
    "        \n",
    "        # storage for captions\n",
    "        captions = []\n",
    "        \n",
    "        # for each sequence, do\n",
    "        for sequence in sequences:\n",
    "            \n",
    "            # predict the caption per sequence\n",
    "            caption = self.predict_caption(sequence)\n",
    "            \n",
    "            # append to the storage of captions\n",
    "            captions.append(caption)\n",
    "            \n",
    "        return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T16:54:49.199041Z",
     "iopub.status.busy": "2022-03-21T16:54:49.198684Z",
     "iopub.status.idle": "2022-03-21T16:54:51.920062Z",
     "shell.execute_reply": "2022-03-21T16:54:51.919133Z",
     "shell.execute_reply.started": "2022-03-21T16:54:49.199012Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the InChI string with the backslash delimiter\n",
    "train_df['InChI_chemical_formula'] = train_df['InChI'].apply(lambda x: x.split('/')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process\n",
    "> This performs all preprocessing steps, mainly: (1) converting InChI string to space separated list of elements,\n",
    "(2) tokenizing the InChI string by creating lists of elements, and (3) computing the actual lengths of each such list. The results are returned in `train_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T17:16:31.184101Z",
     "iopub.status.busy": "2022-03-21T17:16:31.183785Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the InChI string into the chemical formula part and the other layers part\n",
    "train_df['InChI_text'] = (\n",
    "    train_df['InChI_chemical_formula'].apply(split_inchi_formula) \n",
    "    + ' ' \n",
    "    + train_df['InChI'].apply(lambda x: '/'.join(x.split('/')[2:])).apply(split_inchi_layers).values\n",
    "    + ' '\n",
    "    + train_df['InChI'].apply(lambda x: x[x.find('/h'):]).apply(split_inchi_layers).values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T16:59:14.097604Z",
     "iopub.status.busy": "2022-03-21T16:59:14.097379Z",
     "iopub.status.idle": "2022-03-21T16:59:50.010943Z",
     "shell.execute_reply": "2022-03-21T16:59:50.010100Z",
     "shell.execute_reply.started": "2022-03-21T16:59:14.097578Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the train_df in a separate csv\n",
    "train_df.to_csv('../../data/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T16:59:50.012440Z",
     "iopub.status.busy": "2022-03-21T16:59:50.012124Z",
     "iopub.status.idle": "2022-03-21T17:00:40.430870Z",
     "shell.execute_reply": "2022-03-21T17:00:40.429805Z",
     "shell.execute_reply.started": "2022-03-21T16:59:50.012406Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a tokenizer class\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# create a vocabulary of all InChI tokens\n",
    "tokenizer.fit_on_texts(train_df['InChI_text'].values)\n",
    "\n",
    "# save the tokenizer\n",
    "torch.save(tokenizer, '../../data/tokenizer.pth')\n",
    "\n",
    "# store all sequence lengths\n",
    "lengths = []\n",
    "\n",
    "# creates a progress bar around the iterable\n",
    "tk = tqdm(train_df['InChI_text'].values, total=len(train_df))\n",
    "\n",
    "# for each text, i.e. InChI string, in the iterable, do\n",
    "for text in tk:\n",
    "    \n",
    "    # convert text to sequence of characters\n",
    "    seq = tokenizer.text_to_sequence(text)\n",
    "    \n",
    "    # update the caption length (reduced by 2 for <end> and <pad>) and append to the aggregated storage\n",
    "    length = len(seq) - 2\n",
    "    lengths.append(length)\n",
    "    \n",
    "# write down the lengths in the dataframe\n",
    "train_df['InChI_length'] = lengths\n",
    "\n",
    "# save as a pickle file\n",
    "train_df.to_pickle('../../data/train.pkl')\n",
    "\n",
    "print('Saved the train dataframe as a pickle file.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
